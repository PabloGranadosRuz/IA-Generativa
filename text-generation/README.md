# Generaci√≥n de texto con IA Generativa

¬°Hola developer üëãüèª! En esta secci√≥n vas a poder aprender c√≥mo trabajar con modelos de IA Generativa para pedirles que te ayuden a generar texto en base a uno que t√∫ le pases. Adem√°s vamos aprovechar este cap√≠tulo para introducir algunos conceptos que son √∫tiles cuando comienzas en este mundo. El v√≠deo relacionado con este contenido puedes encontrarlo en mi canal de YouTube:

## Introducci√≥n

La generaci√≥n de texto con IA es un campo de la inteligencia artificial que se centra en la creaci√≥n de modelos que puedan generar texto de forma aut√≥noma. Estos modelos se entrenan en grandes cantidades de texto y luego se les pide que generen texto en funci√≥n de una entrada dada. La generaci√≥n de texto con IA se utiliza en una amplia variedad de aplicaciones, como la generaci√≥n de contenido para sitios web, la creaci√≥n de di√°logos para chatbots y la redacci√≥n de informes y art√≠culos. Para mi ejemplo voy a tener como objetivo mejorar t√≠tulos de v√≠deos para mi canal de YouTube, de tal forma que puedas entender estos conceptos con un ejemplo pr√°ctico.

## Qu√© modelos utilizar

Lo primero que necesitas averiguar es qu√© modelos de IA puedes utilizar para esta tarea. La forma m√°s sencilla de averiguarlo es buscar en marketplaces como puede ser el de Ollama o en GitHub Models, o incluso usando la extensi√≥n que te mostr√© en el v√≠deo anterior llamada AI Toolkit for Visual Studio Code. En Github Models puedes encontrar de forma sencilla modelos buscando por `Capability`y eligiendo `Chat/completion` y ver√°s que tenemos diferentes modelos que podemos usar. ¬øCu√°l elegir? Bueno, eso depende de tus necesidades y de tus recursos. Algunos modelos son m√°s grandes y m√°s potentes que otros, pero tambi√©n requieren m√°s recursos para ejecutarse. Si est√°s empezando, te recomiendo que pruebes con un modelo peque√±o y luego vayas subiendo en complejidad a medida que te sientas m√°s c√≥modo. Por ejemplo para este v√≠deo voy a elegir cuatro modelos que est√°n disponibles en GitHub Models:

- `Mistral NeMo`: es un modelo desarrollado por una star-up francesa, Mistral AI, en colaboraci√≥n con NVIDIA. Est√° disponible bajo licencia Apache 2.0 (gratuito). La ventana de contexto es de 128.000 tokens, no es multimodal y soporta m√∫ltiples idiomas.

- `GPT-4o`: es un modelo desarrollado por Open AI, una empresa de inteligencia artificial basada en San Francisco. Es un modelo de pago. Tiene una ventana de contexto de 128.000 tokens, es multimodal y soporta m√∫ltiples idiomas.

- `Deepseek-R1`: es un modelo de lenguaje de √∫ltima generaci√≥n desarrollado por DeepSeek AI, es un modelo gratuito pero tiene un versi√≥n alojada en la nube. Tiene una ventana de contexto de 128.000 tokens, no es multimodal y se puede liar un poco si no le pides las cosas en ingl√©s o chino.

- `Phi-4`:  es un modelo desarrollado por Microsoft y es de pago. Tiene una ventana de contexto de 16.000 tokens, no es multimodal y soporta m√∫ltiples idiomas.

Por otro lado, vamos a ver tambi√©n otros modelos, adem√°s de estos, usando Ollama:

- `Gemma 3`: Es un modelo desarrollado por Google, es un modelo abierto, tiene una ventana de 128.000 tokens, puedes procesar tanto texto como im√°genes y soporta m√∫ltiples idiomas.

- `Llama 3.1`: Es un modelo desarrollado por Meta (Facebook), gratuito, soporta tambi√©n hasta 128.000 tokens y soporta m√∫ltiples idiomas. No es multimodal.

## SDKs y APIs

Una vez que hayas elegido un modelo, necesitas averiguar c√≥mo vas a interactuar con √©l. Afortunadamente, hay muchas opciones disponibles, desde SDKs hasta APIs. Algunos modelos vienen con su propio SDK, pero si no es el caso, puedes utilizar un SDK gen√©rico como Hugging Face o OpenAI. En mi caso, voy a utilizar el SDK de OpenAI.

## Stream o no stream

Cuando est√©s trabajando con un modelo de IA generativa, es importante tener en cuenta si vas a trabajar en modo stream o no. Algunos modelos est√°n dise√±ados para trabajar en modo stream, lo que significa que puedes enviarles una entrada y obtener una salida en tiempo real. Otros modelos no est√°n dise√±ados para trabajar en modo stream, lo que significa que tienes que enviarles toda la entrada de una vez y luego esperar a que te devuelvan toda la salida. Tienes un par de ejemplos de c√≥mo es la experiencia del usuario cuando tienes que esperar que cuando lo vas recibiendo poco a poco. Es habitual que en las interfaces de usuario se utilice el modo stream, mientras que en las aplicaciones de backend se utilice el modo no stream.

